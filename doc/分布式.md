# 技术选型

## spring Cloud 与 dubbo的区别

+ rpc 性能好，但中小型公司没必要追求
+ sc 一整套组件，网关，配置中心，链路，鉴权，熔断降级，可视化界面

# 自己设计一个RPC框架

# Dubbo



## 源码分析

十层，服务

+ 动态代理里实现了rpc框架的核心逻辑

## 扩展性实现

+ 全部接口化实现，动态
+ 基于配置

## 网络通信机制原理

netty,nio,ServerSocketChannel,socketChannel



# springCloud 
## 优点
+ 网络不可用


## SpringCloud 运行架构



## 注册中心

### Eureka

### 运行原理图

### 集群

### Eureka zookeeper注册对比

+ zk集群可以监听通知，添加注销新服务
+ ek集群同步，对等
+ zk cp 同步不完，不可用 ek ap
+ zk 时效快，ek极端需要1分钟
+ zk难支持大量实例，反向通知浪费带宽，ek也不能大量同步集群

### 服务注册高可用

ek 集群

### ek服务发现过慢，优化

优化参数

### 上万服务实例，注册中心如何优化

自研服务中心，分成多个平均分配，并且分主备，没必要要全量消费者，拿自己有用的

### 灰度分布实现

数据库配置表 服务，方法，开关，流量大小（1/int）

## 网关

+ 灰度发布
+ 鉴权
+ 动态路由
+ 性能监控
+ 日志
+ 数据统一缓存
+ 熔断

## kong



## zuul

### 实现动态路由

定时提取数据库路由表

## nginx+lua

## GateWay

### 优势

### 断言

### 路由

### 过滤

## 消息总线

### bus

#### 两种模式

+ 触发客户端，而刷新所有客户端
+ 消息总线触发服务端

actuator

## 每秒10w网关优化

8从16g 几千，32c64G每秒几万

# redis

## 分布式锁

+ SET orderId:lock 随机值 NX PX 30000
+ RedLock

### 如果Redis是集群部署的，那么集群故障时分布式锁还有效么

# zookeeper

## 基础知识

### 使用场景

+ 分布式协调
+ 分布式锁
+ 配置信息管理
+ 高可用
+ 服务注册订阅

## 分布式锁实现原理

创建临时节点为拿到锁，如何没拿到就为临时节点做一个监听器

# 分布式锁

## zookeeper 与 redis实现分布式锁区别



# 分布式会话

+ tomcat + redis: 向tomcat写的时候会同步到redis（tomcat配置文件）,取的时候在redis里取
+ spring Session + redis

# 生产环境部署

网关2台4核8G,注册服务4核8g（1000QPS）两台,数据库mysql(3000qps)16核32g

# 分库分表

## 如何不停机迁移分库分表

+ 不停机双写方案

## 读写分离

### 主从复制原理（异步复制）

基于mysql原生的主从，主库curd时，会产生binlog,从库通过binlog同步给从库relay日志中，从库通过执行sql完成数据同步

### 主从延迟原因

但从库比主库慢一定，因为虽然mysql5.6以后io支持并发，但sql还是单线程

经验数据，主写1000/s，从比主延迟几ms,主库写2000/s,从库延时几十ms.主库达到4000/s.主库就要挂了，从库延迟到几秒

### 半同步复制（数据丢失问题）

介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端。相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间

从库把数据拉到relay，并返回ack

### 解决主从延迟

+ 并行复制（开启但效果不大）
+ 分库（减少压力）
+ 重写逻辑（尽量不要，主库写玩就读分库）
+ 直连主库（不推荐）

### 并行复制



# 如何设计一个高并发系统

## 步骤

1. 拆分系统
2. 缓存、
3. ES
4. 分库分表
5. 读写分离

### 如何设计一个高可用系统

## 基础知识

### 依赖服务如何拖垮整个服务

### 画架构图

4c8G 1000qps 每个服务2台

网关系统 4c8g 每台几百，3，4台 保证高可用

mysql 16c32g 物理机最佳，每秒3，4k

### 每台多大访问量，高峰qps,压测最大qps,接口平均时间延时

tp99 =100s,tp95 = 50ms

### 服务请求重试，会不会出现类似重复下单的问题

+ 插入时用数据库唯一索引就可以
+ 更改基于redis,做一个拦截器。参数为key，做一个防重框架，问题是，人家失败了重试
+ 解决后记录，需要执行1.3s，但请求1s不成功重试，就会一直不成功
+ 执行完了order_id+关键词拼成唯一值，当key存入redis，同样的如果有同样的key写入redis，此时会发现已经有人写过，应该去数据库做一个相反的逻辑，回滚掉

# 分布式事务

## 俩阶段提交

+ 请求阶段
+ 提交阶段

### 问题

+ 单点 协调挂
+ 阻塞
+ 数据不一致

## 三阶段

+ 询问通信是否正常
+ 请求阶段
+ 提交阶段

### 2和3区别

+ 加询问，增大成功率
+ 协调者参与者都有超时机制

### 补救措施

+ 定时任务

### TCC(归滚)

对于协调者和参与者

Tcc+可靠消息最终一致性方案

Try-confirm-Cancel

#### 技术选型

Tcc seata

可靠消息最终一致性 rabbitMq

#### TCC分布式事务框架的核心架构原理

TM(发起事务) RM单独事务 TC（通知总线）

#### TCC事务方案的性能瓶颈T在哪里？能支撑高并发交易场景吗？如何优化

不停的网络请求，额外开销

也需要扩容服务，分库分表

#### 如果公司没有RocketMQ中间件，那你们如何实现最终一致性事务

创建一个可靠消息数据服务，基于数据库完成

#### 你们的分布式锁做过高并发优化吗？能抗下每秒上万并发吗？